{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge"
  ],
  "conda_build_version": "3.24.0",
  "conda_version": "23.3.1",
  "description": "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for\nNeural Network-based text generation systems where the vocabulary size is\npredetermined prior to the neural model training.\n\nSentencePiece implements subword units (e.g., byte-pair-encoding (BPE)\n[[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram\nlanguage model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the\nextension of direct training from raw sentences. SentencePiece allows us to\nmake a purely end-to-end system that does not depend on language-specific\npre/postprocessing.\n",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "feedstock-name": "sentencepiece",
   "final": true,
   "parent_recipe": {
    "name": "sentencepiece-split",
    "path": "/home/conda/recipe_root",
    "version": "0.1.99"
   },
   "recipe-maintainers": [
    "setu4993",
    "rluria14",
    "ndmaxar",
    "oblute",
    "h-vetinari"
   ]
  },
  "home": "https://github.com/google/sentencepiece/",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "license_file": "LICENSE",
  "root_pkgs": [
   "libtiff 4.5.0 ha587672_6",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "reproc-cpp 14.2.4 hcb278e6_0",
   "json5 0.9.5 pyh9f0ad1d_0",
   "libedit 3.1.20191231 he28a2e2_2",
   "python 3.10.11 he550d4f_0_cpython",
   "_openmp_mutex 4.5 2_gnu",
   "traitlets 5.9.0 pyhd8ed1ab_0",
   "libsqlite 3.42.0 h2797004_0",
   "patchelf 0.18.0 h59595ed_0",
   "zstandard 0.19.0 py310hdeb6495_1",
   "libiconv 1.17 h166bdaf_0",
   "anyio 3.7.0 pyhd8ed1ab_1",
   "pybind11-abi 4 hd8ed1ab_3",
   "lzo 2.10 h516909a_1000",
   "urllib3 1.26.15 pyhd8ed1ab_0",
   "pyyaml 6.0 py310h5764c6d_5",
   "openssl 3.1.1 hd590300_1",
   "markdown-it-py 2.2.0 pyhd8ed1ab_0",
   "nbformat 5.9.0 pyhd8ed1ab_0",
   "joblib 1.2.0 pyhd8ed1ab_0",
   "ld_impl_linux-64 2.40 h41732ed_0",
   "packaging 23.1 pyhd8ed1ab_0",
   "pluggy 1.0.0 pyhd8ed1ab_5",
   "importlib-metadata 6.6.0 pyha770c72_0",
   "libmambapy 1.4.2 py310h1428755_0",
   "conda-build 3.24.0 py310hff52083_1",
   "libarchive 3.6.2 h039dbb9_1",
   "libcurl 8.1.2 h409715c_0",
   "ruamel.yaml.clib 0.2.7 py310h1fa729e_1",
   "python-fastjsonschema 2.17.1 pyhd8ed1ab_0",
   "backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0",
   "ncurses 6.3 h27087fc_1",
   "conda-package-streaming 0.8.0 pyhd8ed1ab_0",
   "libbrotlicommon 1.0.9 h166bdaf_8",
   "backports 1.0 pyhd8ed1ab_3",
   "requests 2.31.0 pyhd8ed1ab_0",
   "mdurl 0.1.0 pyhd8ed1ab_0",
   "yaml-cpp 0.7.0 h27087fc_2",
   "pkginfo 1.9.6 pyhd8ed1ab_0",
   "pcre2 10.40 hc3806b6_0",
   "libuuid 2.38.1 h0b41bf4_0",
   "brotli-bin 1.0.9 h166bdaf_8",
   "attrs 23.1.0 pyh71513ae_1",
   "wcwidth 0.2.6 pyhd8ed1ab_0",
   "fmt 9.1.0 h924138e_0",
   "libgomp 13.1.0 he5830b7_0",
   "typing_extensions 4.6.3 pyha770c72_0",
   "ruamel_yaml 0.15.80 py310h5764c6d_1008",
   "libffi 3.4.2 h7f98852_5",
   "charset-normalizer 3.1.0 pyhd8ed1ab_0",
   "libstdcxx-ng 13.1.0 hfd8a6a1_0",
   "libnghttp2 1.52.0 h61bc06f_0",
   "anaconda-client 1.11.2 pyhd8ed1ab_1",
   "sniffio 1.3.0 pyhd8ed1ab_0",
   "jinja2 3.1.2 pyhd8ed1ab_1",
   "anaconda-project 0.11.1 pyhd8ed1ab_0",
   "pycosat 0.6.4 py310h5764c6d_1",
   "importlib_resources 5.12.0 pyhd8ed1ab_0",
   "xz 5.2.6 h166bdaf_0",
   "six 1.16.0 pyh6c4a22f_0",
   "rich 13.4.1 pyhd8ed1ab_0",
   "conda-pack 0.7.0 pyh6c4a22f_0",
   "libwebp-base 1.3.0 h0b41bf4_0",
   "pyrsistent 0.19.3 py310h1fa729e_0",
   "exceptiongroup 1.1.1 pyhd8ed1ab_0",
   "clyent 1.2.2 py_1",
   "tzdata 2023c h71feb2d_0",
   "defusedxml 0.7.1 pyhd8ed1ab_0",
   "setuptools 67.7.2 pyhd8ed1ab_0",
   "libbrotlienc 1.0.9 h166bdaf_8",
   "beautifulsoup4 4.12.2 pyha770c72_0",
   "jsonschema 4.17.3 pyhd8ed1ab_0",
   "perl 5.32.1 2_h7f98852_perl5",
   "filelock 3.12.0 pyhd8ed1ab_0",
   "pillow 9.5.0 py310h582fbeb_1",
   "zipp 3.15.0 pyhd8ed1ab_0",
   "conda-package-handling 2.0.2 pyh38be061_0",
   "bzip2 1.0.8 h7f98852_4",
   "gettext 0.21.1 h27087fc_0",
   "libexpat 2.5.0 hcb278e6_1",
   "brotlipy 0.7.0 py310h5764c6d_1005",
   "toolz 0.12.0 pyhd8ed1ab_0",
   "jupyter_core 5.3.0 py310hff52083_0",
   "mamba 1.4.2 py310h51d5547_0",
   "freetype 2.12.1 hca18f0e_1",
   "ruamel.yaml 0.17.31 py310h2372a71_0",
   "pytz 2023.3 pyhd8ed1ab_0",
   "yaml 0.2.5 h7f98852_2",
   "python-libarchive-c 4.0 py310hff52083_2",
   "krb5 1.20.1 h81ceb04_0",
   "dataclasses 0.8 pyhc8e2a94_3",
   "openjpeg 2.5.0 hfec8fc6_2",
   "python_abi 3.10 3_cp310",
   "pkgutil-resolve-name 1.3.10 pyhd8ed1ab_0",
   "lz4-c 1.9.4 hcb278e6_0",
   "zstd 1.5.2 h3eb15da_6",
   "psutil 5.9.5 py310h1fa729e_0",
   "prompt-toolkit 3.0.38 pyha770c72_0",
   "watchgod 0.8.2 pyhd8ed1ab_0",
   "prompt_toolkit 3.0.38 hd8ed1ab_0",
   "py-lief 0.12.3 py310hd8f1fbe_0",
   "soupsieve 2.3.2.post1 pyhd8ed1ab_0",
   "_libgcc_mutex 0.1 conda_forge",
   "boltons 23.0.0 pyhd8ed1ab_0",
   "libxcb 1.15 h0b41bf4_0",
   "libbrotlidec 1.0.9 h166bdaf_8",
   "tomli 2.0.1 pyhd8ed1ab_0",
   "tk 8.6.12 h27826a3_0",
   "liblief 0.12.3 h27087fc_0",
   "idna 3.4 pyhd8ed1ab_0",
   "keyutils 1.6.1 h166bdaf_0",
   "libjpeg-turbo 2.1.5.1 h0b41bf4_0",
   "certifi 2023.5.7 pyhd8ed1ab_0",
   "libgcc-ng 13.1.0 he5830b7_0",
   "icu 72.1 hcb278e6_0",
   "xorg-libxau 1.0.11 hd590300_0",
   "pycparser 2.21 pyhd8ed1ab_0",
   "tornado 6.3.2 py310h2372a71_0",
   "glob2 0.7 py_0",
   "curl 8.1.2 h409715c_0",
   "brotli 1.0.9 h166bdaf_8",
   "lcms2 2.15 haa2dc70_1",
   "libev 4.33 h516909a_1",
   "pthread-stubs 0.4 h36c2ea0_1001",
   "libdeflate 1.18 h0b41bf4_0",
   "wheel 0.40.0 pyhd8ed1ab_0",
   "readline 8.2 h8228510_1",
   "lerc 4.0.0 h27087fc_0",
   "libzlib 1.2.13 h166bdaf_4",
   "libssh2 1.11.0 h0841786_0",
   "ca-certificates 2023.5.7 hbcca054_0",
   "libmamba 1.4.2 hcea66bb_0",
   "xorg-libxdmcp 1.1.3 h7f98852_0",
   "git 2.41.0 pl5321h86e50cf_0",
   "typing-extensions 4.6.3 hd8ed1ab_0",
   "pysocks 1.7.1 pyha2e5f31_6",
   "chardet 5.1.0 py310hff52083_0",
   "markupsafe 2.1.3 py310h2372a71_0",
   "patch 2.7.6 h7f98852_1002",
   "jsonpatch 1.32 pyhd8ed1ab_0",
   "pygments 2.15.1 pyhd8ed1ab_0",
   "libnsl 2.0.0 h7f98852_0",
   "su-exec 0.2 h166bdaf_1003",
   "pip 23.1.2 pyhd8ed1ab_0",
   "ripgrep 13.0.0 h2f28480_2",
   "libpng 1.6.39 h753d276_0",
   "reproc 14.2.4 h0b41bf4_0",
   "jsonpointer 2.0 py_0",
   "requests-toolbelt 1.0.0 pyhd8ed1ab_0",
   "pyopenssl 23.2.0 pyhd8ed1ab_1",
   "cryptography 41.0.1 py310h75e40e8_0",
   "platformdirs 3.5.1 pyhd8ed1ab_0",
   "libsolv 0.7.23 h3eb15da_0",
   "conda 23.3.1 py310hff52083_0",
   "tini 0.19.0 h166bdaf_1",
   "colorama 0.4.6 pyhd8ed1ab_0",
   "tqdm 4.65.0 pyhd8ed1ab_1",
   "c-ares 1.19.1 hd590300_0",
   "boa 0.14.0 pyhd8ed1ab_4",
   "cffi 1.15.1 py310h255011f_3",
   "libxml2 2.11.4 h0d562d8_0",
   "oniguruma 6.9.8 h166bdaf_0",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "conda-forge-ci-setup 3.31.0 py310hce54274_100",
   "conda-forge-metadata 0.5.0 pyhd8ed1ab_0",
   "conda-oci-mirror 0.1.0 pyhd8ed1ab_0",
   "click 8.1.3 unix_pyhd8ed1ab_2",
   "oras-py 0.1.14 pyhd8ed1ab_0",
   "jq 1.6 h36c2ea0_1000",
   "conda-env 2.6.0 1"
  ],
  "summary": "Unsupervised text tokenizer for Neural Network-based text generation.",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "cdt_name": "cos6",
  "channel_sources": "conda-forge",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "cxx_compiler_version": "12",
  "docker_image": "quay.io/condaforge/linux-anvil-cos7-x86_64",
  "extend_keys": [
   "pin_run_as_build",
   "ignore_build_only_deps",
   "extend_keys",
   "ignore_version"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "libabseil": "20230125",
  "libprotobuf": "3.21",
  "lua": "5",
  "numpy": "1.21",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.10.* *_cpython",
  "r_base": "3.5",
  "target_platform": "linux-64"
 },
 "conda_pkg_format": "2",
 "files": [
  "lib/python3.10/site-packages/sentencepiece-0.1.99.dist-info/INSTALLER",
  "lib/python3.10/site-packages/sentencepiece-0.1.99.dist-info/METADATA",
  "lib/python3.10/site-packages/sentencepiece-0.1.99.dist-info/RECORD",
  "lib/python3.10/site-packages/sentencepiece-0.1.99.dist-info/REQUESTED",
  "lib/python3.10/site-packages/sentencepiece-0.1.99.dist-info/WHEEL",
  "lib/python3.10/site-packages/sentencepiece-0.1.99.dist-info/direct_url.json",
  "lib/python3.10/site-packages/sentencepiece/__init__.py",
  "lib/python3.10/site-packages/sentencepiece/_sentencepiece.cpython-310-x86_64-linux-gnu.so",
  "lib/python3.10/site-packages/sentencepiece/_version.py",
  "lib/python3.10/site-packages/sentencepiece/sentencepiece_model_pb2.py",
  "lib/python3.10/site-packages/sentencepiece/sentencepiece_pb2.py"
 ],
 "index": {
  "arch": "x86_64",
  "build": "py310hebdb9f0_0",
  "build_number": 0,
  "depends": [
   "libgcc-ng >=12",
   "libprotobuf >=3.21.12,<3.22.0a0",
   "libsentencepiece 0.1.99 h180e1df_0",
   "libstdcxx-ng >=12",
   "python >=3.10,<3.11.0a0",
   "python_abi 3.10.* *_cp310"
  ],
  "license": "Apache-2.0",
  "license_family": "Apache",
  "name": "sentencepiece-python",
  "platform": "linux",
  "subdir": "linux-64",
  "timestamp": 1686036039166,
  "version": "0.1.99"
 },
 "metadata_version": 1,
 "name": "sentencepiece-python",
 "raw_recipe": "# This file created by conda-build 3.24.0\n# ------------------------------------------------\n\npackage:\n  name: sentencepiece-python\n  version: 0.1.99\nsource:\n  patches:\n    - patches/0001-do-not-mix-static-shared-builds.patch\n    - patches/0002-do-not-build-vendored-abseil-libprotobuf-lite.patch\n    - patches/0003-consistently-use-absolute-paths-for-CMAKE_INSTALL_-D.patch\n    - patches/0004-ACTUALLY-use-external-absl.patch\n    - patches/0005-stop-pretending-sp-glue-code-belongs-in-third_party-.patch\n    - patches/0006-point-to-our-libs-headers-for-windows-in-setup.py.patch\n    - patches/0007-also-install-pkg-config-files-on-windows.patch\n    - patches/0008-create-and-install-CMake-metadata.patch\n  sha256: 63617eaf56c7a3857597dcd8780461f57dd21381b56a27716ef7d7e02e14ced4\n  url: https://github.com/google/sentencepiece/archive/refs/tags/v0.1.99.tar.gz\nbuild:\n  noarch: false\n  noarch_python: false\n  number: '0'\n  script: build-pkg.sh\n  string: py310hebdb9f0_0\nrequirements:\n  build:\n    - _libgcc_mutex 0.1 conda_forge\n    - _openmp_mutex 4.5 2_gnu\n    - binutils_impl_linux-64 2.39 he00db2b_1\n    - binutils_linux-64 2.39 h5fc0e48_13\n    - gcc_impl_linux-64 12.2.0 hcc96c02_19\n    - gcc_linux-64 12.2.0 h4798a0e_13\n    - gxx_impl_linux-64 12.2.0 hcc96c02_19\n    - gxx_linux-64 12.2.0 hb41e900_13\n    - kernel-headers_linux-64 2.6.32 he073ed8_15\n    - ld_impl_linux-64 2.39 hcc3a1bd_1\n    - libgcc-devel_linux-64 12.2.0 h3b97bd3_19\n    - libgcc-ng 13.1.0 he5830b7_0\n    - libgomp 13.1.0 he5830b7_0\n    - libsanitizer 12.2.0 h46fd767_19\n    - libstdcxx-devel_linux-64 12.2.0 h3b97bd3_19\n    - libstdcxx-ng 13.1.0 hfd8a6a1_0\n    - pkg-config 0.29.2 h36c2ea0_1008\n    - sysroot_linux-64 2.12 he073ed8_15\n  host:\n    - _libgcc_mutex 0.1 conda_forge\n    - _openmp_mutex 4.5 2_gnu\n    - bzip2 1.0.8 h7f98852_4\n    - ca-certificates 2023.5.7 hbcca054_0\n    - ld_impl_linux-64 2.40 h41732ed_0\n    - libffi 3.4.2 h7f98852_5\n    - libgcc-ng 13.1.0 he5830b7_0\n    - libgomp 13.1.0 he5830b7_0\n    - libnsl 2.0.0 h7f98852_0\n    - libprotobuf 3.21.12 h3eb15da_0\n    - libsentencepiece 0.1.99 h180e1df_0\n    - libsqlite 3.42.0 h2797004_0\n    - libstdcxx-ng 13.1.0 hfd8a6a1_0\n    - libuuid 2.38.1 h0b41bf4_0\n    - libzlib 1.2.13 h166bdaf_4\n    - ncurses 6.3 h27087fc_1\n    - openssl 3.1.1 hd590300_1\n    - pip 23.1.2 pyhd8ed1ab_0\n    - python 3.10.11 he550d4f_0_cpython\n    - readline 8.2 h8228510_1\n    - setuptools 67.7.2 pyhd8ed1ab_0\n    - tk 8.6.12 h27826a3_0\n    - tzdata 2023c h71feb2d_0\n    - wheel 0.40.0 pyhd8ed1ab_0\n    - xz 5.2.6 h166bdaf_0\n  run:\n    - libgcc-ng >=12\n    - libprotobuf >=3.21.12,<3.22.0a0\n    - libsentencepiece 0.1.99 h180e1df_0\n    - libstdcxx-ng >=12\n    - python >=3.10,<3.11.0a0\n    - python_abi 3.10.* *_cp310\ntest:\n  commands:\n    - pip check\n    - cd python && pytest test\n  imports:\n    - sentencepiece\n  requires:\n    - pip\n    - pytest\n  source_files:\n    - data\n    - python/test\nabout:\n  description: 'SentencePiece is an unsupervised text tokenizer and detokenizer mainly\n    for\n\n    Neural Network-based text generation systems where the vocabulary size is\n\n    predetermined prior to the neural model training.\n\n\n    SentencePiece implements subword units (e.g., byte-pair-encoding (BPE)\n\n    [[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram\n\n    language model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the\n\n    extension of direct training from raw sentences. SentencePiece allows us to\n\n    make a purely end-to-end system that does not depend on language-specific\n\n    pre/postprocessing.\n\n    '\n  home: https://github.com/google/sentencepiece/\n  license: Apache-2.0\n  license_family: Apache\n  license_file: LICENSE\n  summary: Unsupervised text tokenizer for Neural Network-based text generation.\nextra:\n  copy_test_source_files: true\n  feedstock-name: sentencepiece\n  final: true\n  recipe-maintainers:\n    - h-vetinari\n    - ndmaxar\n    - oblute\n    - rluria14\n    - setu4993\n",
 "rendered_recipe": {
  "about": {
   "description": "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for\nNeural Network-based text generation systems where the vocabulary size is\npredetermined prior to the neural model training.\n\nSentencePiece implements subword units (e.g., byte-pair-encoding (BPE)\n[[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram\nlanguage model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the\nextension of direct training from raw sentences. SentencePiece allows us to\nmake a purely end-to-end system that does not depend on language-specific\npre/postprocessing.\n",
   "home": "https://github.com/google/sentencepiece/",
   "license": "Apache-2.0",
   "license_family": "Apache",
   "license_file": "LICENSE",
   "summary": "Unsupervised text tokenizer for Neural Network-based text generation."
  },
  "build": {
   "noarch": false,
   "noarch_python": false,
   "number": "0",
   "script": "build-pkg.sh",
   "string": "py310hebdb9f0_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "feedstock-name": "sentencepiece",
   "final": true,
   "recipe-maintainers": [
    "h-vetinari",
    "ndmaxar",
    "oblute",
    "rluria14",
    "setu4993"
   ]
  },
  "package": {
   "name": "sentencepiece-python",
   "version": "0.1.99"
  },
  "requirements": {
   "build": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 2_gnu",
    "binutils_impl_linux-64 2.39 he00db2b_1",
    "binutils_linux-64 2.39 h5fc0e48_13",
    "gcc_impl_linux-64 12.2.0 hcc96c02_19",
    "gcc_linux-64 12.2.0 h4798a0e_13",
    "gxx_impl_linux-64 12.2.0 hcc96c02_19",
    "gxx_linux-64 12.2.0 hb41e900_13",
    "kernel-headers_linux-64 2.6.32 he073ed8_15",
    "ld_impl_linux-64 2.39 hcc3a1bd_1",
    "libgcc-devel_linux-64 12.2.0 h3b97bd3_19",
    "libgcc-ng 13.1.0 he5830b7_0",
    "libgomp 13.1.0 he5830b7_0",
    "libsanitizer 12.2.0 h46fd767_19",
    "libstdcxx-devel_linux-64 12.2.0 h3b97bd3_19",
    "libstdcxx-ng 13.1.0 hfd8a6a1_0",
    "pkg-config 0.29.2 h36c2ea0_1008",
    "sysroot_linux-64 2.12 he073ed8_15"
   ],
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 2_gnu",
    "bzip2 1.0.8 h7f98852_4",
    "ca-certificates 2023.5.7 hbcca054_0",
    "ld_impl_linux-64 2.40 h41732ed_0",
    "libffi 3.4.2 h7f98852_5",
    "libgcc-ng 13.1.0 he5830b7_0",
    "libgomp 13.1.0 he5830b7_0",
    "libnsl 2.0.0 h7f98852_0",
    "libprotobuf 3.21.12 h3eb15da_0",
    "libsentencepiece 0.1.99 h180e1df_0",
    "libsqlite 3.42.0 h2797004_0",
    "libstdcxx-ng 13.1.0 hfd8a6a1_0",
    "libuuid 2.38.1 h0b41bf4_0",
    "libzlib 1.2.13 h166bdaf_4",
    "ncurses 6.3 h27087fc_1",
    "openssl 3.1.1 hd590300_1",
    "pip 23.1.2 pyhd8ed1ab_0",
    "python 3.10.11 he550d4f_0_cpython",
    "readline 8.2 h8228510_1",
    "setuptools 67.7.2 pyhd8ed1ab_0",
    "tk 8.6.12 h27826a3_0",
    "tzdata 2023c h71feb2d_0",
    "wheel 0.40.0 pyhd8ed1ab_0",
    "xz 5.2.6 h166bdaf_0"
   ],
   "run": [
    "libgcc-ng >=12",
    "libprotobuf >=3.21.12,<3.22.0a0",
    "libsentencepiece 0.1.99 h180e1df_0",
    "libstdcxx-ng >=12",
    "python >=3.10,<3.11.0a0",
    "python_abi 3.10.* *_cp310"
   ]
  },
  "source": {
   "patches": [
    "patches/0001-do-not-mix-static-shared-builds.patch",
    "patches/0002-do-not-build-vendored-abseil-libprotobuf-lite.patch",
    "patches/0003-consistently-use-absolute-paths-for-CMAKE_INSTALL_-D.patch",
    "patches/0004-ACTUALLY-use-external-absl.patch",
    "patches/0005-stop-pretending-sp-glue-code-belongs-in-third_party-.patch",
    "patches/0006-point-to-our-libs-headers-for-windows-in-setup.py.patch",
    "patches/0007-also-install-pkg-config-files-on-windows.patch",
    "patches/0008-create-and-install-CMake-metadata.patch"
   ],
   "sha256": "63617eaf56c7a3857597dcd8780461f57dd21381b56a27716ef7d7e02e14ced4",
   "url": "https://github.com/google/sentencepiece/archive/refs/tags/v0.1.99.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "cd python && pytest test"
   ],
   "imports": [
    "sentencepiece"
   ],
   "requires": [
    "pip",
    "pytest"
   ],
   "source_files": [
    "data",
    "python/test"
   ]
  }
 },
 "version": "0.1.99"
}