{
 "about": {
  "channels": [
   "conda-forge",
   "defaults"
  ],
  "conda_build_version": "3.10.1",
  "conda_private": false,
  "conda_version": "4.5.3",
  "description": "This project seeks to build a Python software package that\nconsists of a comprehensive and scalable set of string tokenizers\n(such as alphabetical tokenizers, whitespace tokenizers) and\n",
  "dev_url": "https://github.com/anhaidgroup/py_stringmatching",
  "doc_url": "http://anhaidgroup.github.io/py_stringmatching/",
  "env_vars": {
   "CIO_TEST": "<not set>",
   "CONDA_DEFAULT_ENV": "base",
   "CONDA_ENVS_PATH": "<not set>",
   "LD_LIBRARY_PATH": "/opt/rh/devtoolset-2/root/usr/lib64:/opt/rh/devtoolset-2/root/usr/lib",
   "PATH": "/opt/conda/bin:/opt/rh/devtoolset-2/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/conda/bin",
   "PYTHONHOME": "<not set>",
   "PYTHONPATH": "/opt/rh/devtoolset-2/root/usr/lib64/python2.6/site-packages:/opt/rh/devtoolset-2/root/usr/lib/python2.6/site-packages"
  },
  "home": "https://sites.google.com/site/anhaidgroup/projects/py_stringmatching",
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "license_file": "LICENSE",
  "root_pkgs": [
   "cffi 1.11.5 py36_0",
   "cryptography 2.2.1 py36_0",
   "xz 5.2.3 0",
   "packaging 17.1 py_0",
   "requests 2.18.4 py36_1",
   "certifi 2018.4.16 py36_0",
   "readline 7.0 0",
   "chardet 3.0.4 py36_0",
   "pyopenssl 17.5.0 py36_1",
   "urllib3 1.22 py36_0",
   "zlib 1.2.11 0",
   "yaml 0.1.7 0",
   "pycparser 2.18 py36_0",
   "asn1crypto 0.24.0 py36_0",
   "libffi 3.2.1 3",
   "tk 8.6.7 0",
   "setuptools 39.0.1 py36_0",
   "ruamel_yaml 0.15.35 py36_0",
   "pysocks 1.6.8 py36_1",
   "pip 9.0.3 py36_0",
   "idna 2.6 py36_1",
   "wheel 0.31.0 py36_0",
   "python 3.6.5 1",
   "pycosat 0.6.3 py36_0",
   "ncurses 5.9 10",
   "six 1.11.0 py36_1",
   "ca-certificates 2018.4.16 0",
   "pyparsing 2.2.0 py36_0",
   "sqlite 3.20.1 2",
   "conda-env 2.6.0 0",
   "openssl 1.0.2o 0",
   "traitlets 4.3.2 py36_0",
   "pytz 2018.4 py_0",
   "git 2.14.2 3",
   "curl 7.59.0 1",
   "glob2 0.5 py36_0",
   "conda-verify 2.0.0 py36_0",
   "filelock 3.0.4 py36_0",
   "jsonschema 2.6.0 py36_1",
   "anaconda-client 1.6.14 py_0",
   "pyyaml 3.12 py36_1",
   "beautifulsoup4 4.6.0 py36_0",
   "patchelf 0.9 2",
   "clyent 1.2.2 py36_0",
   "tini 0.18.0 0",
   "ipython_genutils 0.2.0 py36_0",
   "libiconv 1.15 0",
   "krb5 1.14.6 0",
   "expat 2.2.5 0",
   "conda 4.5.3 py36_0",
   "nbformat 4.4.0 py36_0",
   "decorator 4.3.0 py_0",
   "conda-forge-ci-setup 1.3.3 0",
   "libssh2 1.8.0 2",
   "conda-build 3.10.1 py36_0",
   "pkginfo 1.4.2 py36_0",
   "jinja2 2.10 py36_0",
   "jupyter_core 4.4.0 py_0",
   "markupsafe 1.0 py36_0",
   "psutil 5.4.5 py36_0",
   "python-dateutil 2.7.2 py_0",
   "gosu 1.10 0"
  ],
  "summary": "Python library for string matching."
 },
 "conda_build_config": {
  "c_compiler": "toolchain_c",
  "cpu_optimization_target": "nocona",
  "cxx_compiler": "gxx",
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": "python",
  "lua": "5",
  "numpy": "1.9",
  "perl": "5.26.0",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x.x",
    "min_pin": "x.x.x"
   }
  },
  "python": "2.7",
  "r_base": "3.4",
  "target_platform": "linux-64"
 },
 "files": [
  "lib/python2.7/site-packages/py_stringmatching-0.4.0-py2.7.egg-info/PKG-INFO",
  "lib/python2.7/site-packages/py_stringmatching-0.4.0-py2.7.egg-info/not-zip-safe",
  "lib/python2.7/site-packages/py_stringmatching/__init__.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/__init__.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/affine.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/bag_distance.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cosine.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/__init__.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_affine.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_affine.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_jaro.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_jaro.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_jaro_winkler.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_jaro_winkler.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_levenshtein.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_levenshtein.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_needleman_wunsch.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_needleman_wunsch.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_smith_waterman.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_smith_waterman.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_utils.c",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/cython/cython_utils.so",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/dice.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/editex.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/generalized_jaccard.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/hamming_distance.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/hybrid_similarity_measure.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/jaccard.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/jaro.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/jaro_winkler.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/levenshtein.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/monge_elkan.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/needleman_wunsch.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/overlap_coefficient.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/partial_ratio.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/partial_token_sort.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/phonetic_similarity_measure.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/ratio.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/sequence_similarity_measure.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/similarity_measure.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/smith_waterman.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/soft_tfidf.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/soundex.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/tfidf.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/token_similarity_measure.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/token_sort.py",
  "lib/python2.7/site-packages/py_stringmatching/similarity_measure/tversky_index.py",
  "lib/python2.7/site-packages/py_stringmatching/tests/__init__.py",
  "lib/python2.7/site-packages/py_stringmatching/tests/test_sim_Soundex.py",
  "lib/python2.7/site-packages/py_stringmatching/tests/test_simfunctions.py",
  "lib/python2.7/site-packages/py_stringmatching/tests/test_tokenizers.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/__init__.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/alphabetic_tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/alphanumeric_tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/definition_tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/delimiter_tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/qgram_tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/tokenizer/whitespace_tokenizer.py",
  "lib/python2.7/site-packages/py_stringmatching/utils.py"
 ],
 "index": {
  "arch": "x86_64",
  "build": "py27h7eb728f_0",
  "build_number": 0,
  "depends": [
   "libgcc-ng >=4.9",
   "numpy >=1.9.3,<2.0a0",
   "python >=2.7,<2.8.0a0",
   "six"
  ],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "name": "py_stringmatching",
  "platform": "linux",
  "subdir": "linux-64",
  "timestamp": 1525746006945,
  "version": "0.4.0"
 },
 "metadata_version": 1,
 "name": "py_stringmatching",
 "raw_recipe": "{% set name = \"py_stringmatching\" %}\n{% set version = \"0.4.0\" %}\n{% set sha256 = \"64794c179cefece8f337c9f458dfdce937b08efabad220e2dcdad81be3e95a66\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  fn: {{ name }}-{{ version }}.tar.gz\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: {{ sha256 }}\n\nbuild:\n  number: 0\n  script: python -m pip install --no-deps --ignore-installed .\n  skip: True  # [not x86_64]\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n    - msinttypes  # [vc9]\n  host:\n    - python\n    - pip\n    - setuptools\n    - cython\n    - numpy\n    - six\n  run:\n    - python\n    - {{ pin_compatible('numpy') }}\n    - six\n\ntest:\n  imports:\n    - py_stringmatching\n    - py_stringmatching.similarity_measure\n    - py_stringmatching.tests\n    - py_stringmatching.tokenizer\n\nabout:\n  home: https://sites.google.com/site/anhaidgroup/projects/py_stringmatching\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE\n  summary: 'Python library for string matching.'\n  description: |\n    This project seeks to build a Python software package that \n    consists of a comprehensive and scalable set of string tokenizers \n    (such as alphabetical tokenizers, whitespace tokenizers) and \n  doc_url: http://anhaidgroup.github.io/py_stringmatching/\n  dev_url: https://github.com/anhaidgroup/py_stringmatching\n\nextra:\n  recipe-maintainers:\n    - pjmartinkus\n",
 "rendered_recipe": {
  "about": {
   "description": "This project seeks to build a Python software package that\nconsists of a comprehensive and scalable set of string tokenizers\n(such as alphabetical tokenizers, whitespace tokenizers) and\n",
   "dev_url": "https://github.com/anhaidgroup/py_stringmatching",
   "doc_url": "http://anhaidgroup.github.io/py_stringmatching/",
   "home": "https://sites.google.com/site/anhaidgroup/projects/py_stringmatching",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": "LICENSE",
   "summary": "Python library for string matching."
  },
  "build": {
   "number": "0",
   "script": "python -m pip install --no-deps --ignore-installed .",
   "string": "py27h7eb728f_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "pjmartinkus"
   ]
  },
  "package": {
   "name": "py_stringmatching",
   "version": "0.4.0"
  },
  "requirements": {
   "build": [
    "toolchain 2.1.3 0",
    "toolchain_c_linux-64 2.1.3 0"
   ],
   "host": [
    "blas 1.1 openblas",
    "ca-certificates 2018.4.16 0",
    "certifi 2018.4.16 py27_0",
    "cython 0.28.2 py27_0",
    "libgcc-ng 7.2.0 hdf63c60_3",
    "libgfortran 3.0.0 1",
    "ncurses 5.9 10",
    "numpy 1.9.3 py27_blas_openblas_203",
    "openblas 0.2.20 7",
    "openssl 1.0.2o 0",
    "pip 9.0.3 py27_0",
    "python 2.7.14 5",
    "readline 7.0 0",
    "setuptools 39.1.0 py27_0",
    "six 1.11.0 py27_1",
    "sqlite 3.20.1 2",
    "tk 8.6.7 0",
    "wheel 0.31.0 py27_0",
    "zlib 1.2.11 0"
   ],
   "run": [
    "libgcc-ng >=4.9",
    "numpy >=1.9.3,<2.0a0",
    "python >=2.7,<2.8.0a0",
    "six"
   ]
  },
  "source": {
   "fn": "py_stringmatching-0.4.0.tar.gz",
   "sha256": "64794c179cefece8f337c9f458dfdce937b08efabad220e2dcdad81be3e95a66",
   "url": "https://pypi.io/packages/source/p/py_stringmatching/py_stringmatching-0.4.0.tar.gz"
  },
  "test": {
   "imports": [
    "py_stringmatching",
    "py_stringmatching.similarity_measure",
    "py_stringmatching.tests",
    "py_stringmatching.tokenizer"
   ]
  }
 },
 "version": "0.4.0"
}